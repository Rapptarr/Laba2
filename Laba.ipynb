{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8qaqVjf1h3Q"
      },
      "source": [
        "# Char-based text generation with LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yc5cs__-1h3V"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "eg--g0_y1h3X",
        "outputId": "52249974-6803-4311-ea24-925447526bb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', 'о', 'е', 'а', 'н', 'т', 'и', 'с', 'р', 'л', 'в', '\\n', 'д', 'м', 'к', 'ы', ',', 'ь', 'й', 'у', 'п', 'б', 'з', 'г', 'я', 'ч', 'ж', 'х', '!', 'ш', 'ц', '.', 'В', 'Т', 'ю', 'С', '—', 'Н', 'П', 'щ', 'О', 'И', 'К', ':', 'Г', '?', 'Ч', 'М', 'Д', 'Б', 'ф', 'А', 'З', 'э', ';', 'Р', 'Л', 'Я', 'У', '-', 'Е', '…', 'Ф', 'Э', '«', 'Х', '(', ')', '»', 'Ц', 'ъ', 'Ш', 'Ж', 'Щ']\n"
          ]
        }
      ],
      "source": [
        "TRAIN_TEXT_FILE_PATH = 'train_text.txt'\n",
        "\n",
        "with open(TRAIN_TEXT_FILE_PATH) as text_file:\n",
        "    text_sample = text_file.readlines()\n",
        "text_sample = ' '.join(text_sample)\n",
        "\n",
        "def text_to_seq(text_sample):\n",
        "    char_counts = Counter(text_sample)\n",
        "    char_counts = sorted(char_counts.items(), key = lambda x: x[1], reverse=True)\n",
        "\n",
        "    sorted_chars = [char for char, _ in char_counts]\n",
        "    print(sorted_chars)\n",
        "    char_to_idx = {char: index for index, char in enumerate(sorted_chars)}\n",
        "    idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
        "    sequence = np.array([char_to_idx[char] for char in text_sample])\n",
        "\n",
        "    return sequence, char_to_idx, idx_to_char\n",
        "\n",
        "sequence, char_to_idx, idx_to_char = text_to_seq(text_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rYAmED1c1h3Y"
      },
      "outputs": [],
      "source": [
        "SEQ_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "def get_batch(sequence):\n",
        "    trains = []\n",
        "    targets = []\n",
        "    for _ in range(BATCH_SIZE):\n",
        "        batch_start = np.random.randint(0, len(sequence) - SEQ_LEN)\n",
        "        chunk = sequence[batch_start: batch_start + SEQ_LEN]\n",
        "        train = torch.LongTensor(chunk[:-1]).view(-1, 1)\n",
        "        target = torch.LongTensor(chunk[1:]).view(-1, 1)\n",
        "        trains.append(train)\n",
        "        targets.append(target)\n",
        "    return torch.stack(trains, dim=0), torch.stack(targets, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FjW88hBn1h3Z"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, char_to_idx, idx_to_char, start_text=' ', prediction_len=200, temp=0.3):\n",
        "    hidden = model.init_hidden()\n",
        "    idx_input = [char_to_idx[char] for char in start_text]\n",
        "    train = torch.LongTensor(idx_input).view(-1, 1, 1).to(device)\n",
        "    predicted_text = start_text\n",
        "\n",
        "    _, hidden = model(train, hidden)\n",
        "\n",
        "    inp = train[-1].view(-1, 1, 1)\n",
        "\n",
        "    for i in range(prediction_len):\n",
        "        output, hidden = model(inp.to(device), hidden)\n",
        "        output_logits = output.cpu().data.view(-1)\n",
        "        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()\n",
        "        top_index = np.random.choice(len(char_to_idx), p=p_next)\n",
        "        inp = torch.LongTensor([top_index]).view(-1, 1, 1).to(device)\n",
        "        predicted_char = idx_to_char[top_index]\n",
        "        predicted_text += predicted_char\n",
        "\n",
        "    return predicted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MHAofBwe1h3Z"
      },
      "outputs": [],
      "source": [
        "class TextRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, embedding_size, n_layers=1):\n",
        "        super(TextRNN, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.input_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.encoder(x).squeeze(2)\n",
        "        out, (ht1, ct1) = self.lstm(x, hidden)\n",
        "        out = self.dropout(out)\n",
        "        x = self.fc(out)\n",
        "        return x, (ht1, ct1)\n",
        "\n",
        "    def init_hidden(self, batch_size=1):\n",
        "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device),\n",
        "               torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "y3KuuVCL1h3a",
        "outputId": "66133584-cd19-4c0a-a64c-062c828bc06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.167424602508545\n",
            " вота срото тесто вом свосто то воте потоке сел стесто восто баде воки се лозот сролодером вевовий соталет сно росте но пато вол веда песта полити сесто тоно поти сено ссро вом сна вем вас вовень пето \n",
            "Loss: 2.507268133163452\n",
            " вемной дорей веланья\n",
            " И торой кора вордой вела,\n",
            " Отсе мезденья стом тола вемной\n",
            " То рового слава,\n",
            " И провова не веденья\n",
            " Стора стобронье не в ворой пода варенья,\n",
            " Словет вам стобом вал ватонь верной,\n",
            "\n",
            "Loss: 2.2590175819396974\n",
            " раздерной в не ваченья\n",
            " В ты сорда слез ведный на пумелей\n",
            " В не поренья в сорный праветь сомный престреть пакрен,\n",
            " В ты поковь сордолиный был порей провью в собой!\n",
            " Ты верной слесть в грасти стил нень\n",
            "Loss: 2.057433841228485\n",
            " пердца в сердца,\n",
            " С твой стал свои в собиль,\n",
            " В не вроствой стого в поровой в тобой\n",
            " В тобой стал на слести ствоей!\n",
            " О покольсти провь на в небо нам\n",
            " Она мели пороны сердца кровь\n",
            " На провь полино пори\n",
            "Loss: 1.8416294407844545\n",
            " пар морей!\n",
            " Где соберит воспомовила,\n",
            " Ты давы все поворенья\n",
            " Востора все призе долов.\n",
            " В твои думал сердца в велиний\n",
            " На верит ветвой стод поровов.\n",
            " В тобой порда гроз нам славы,\n",
            " В обольство был ты п\n",
            "Loss: 1.635311336517334\n",
            " раздава,\n",
            " И посталенной в провавой любви поколенья\n",
            " В твоем твои пред она пред — собни прокий!\n",
            " \n",
            " Подовсе свое больной\n",
            " И постал он — черний властья\n",
            " Все с утратой лись все дем — все смертной\n",
            " Твой ст\n",
            "Loss: 1.4301157951354981\n",
            " обланый любви поцелуй!\n",
            " \n",
            " Не волы пред нам провавой веком\n",
            " В небо с утроз предков!\n",
            " В твоей стод свет в призедомной\n",
            " Что все пасть беспоковила славой,\n",
            " Ты с утрато, что в пред был солданья\n",
            " Восталени,\n",
            "Loss: 1.2565598726272582\n",
            " верном свобода\n",
            " В весем презраны была и пумель,\n",
            " То сокрушенья рука,\n",
            " На поры вых сломила,\n",
            " Твой потобить в пред нам дворцов.\n",
            " \n",
            " Вох смер пред над в предной,\n",
            " И пасть беспот сердца бевший,\n",
            " Где в пред\n",
            "Loss: 1.1077882695198058\n",
            " отвраний кровавый,\n",
            " Ты был верить людевый,\n",
            " Твой пасть примело в порывами,\n",
            " Кровь соследить поленный для людвых сердца,\n",
            " На верить людевы,\n",
            " Не всесть в призал — сердца, в племени!\n",
            " Но не знал сольнен,\n",
            "Loss: 0.9810188293457032\n",
            " она стратона,\n",
            " Но всем пример море светок\n",
            " Подобно вы, что верит!\n",
            " Он — единого волну,\n",
            " То дай стыда снесть, пред былом\n",
            " Все небо стратоко\n",
            " Не всеск ть падений\n",
            " И вергнутый злодей!\n",
            " Когда когда полнос\n",
            "Loss: 0.8799455368518829\n",
            " верит не славит верном,\n",
            " Поль твои мир не совордьбы столя:\n",
            " О, сенничей в грез!\n",
            " Как войска т вотки пор околла:\n",
            " Верь действой бой\n",
            " Вледениль стыда с тобой покойнуть —\n",
            " Заменный духом бога,\n",
            " Струн лег\n",
            "Loss: 0.7913268756866455\n",
            " веришь гросить т пырем\n",
            " В уражденья расступенниле\n",
            " Под сомолана страх, из первый!\n",
            " \n",
            " Не не могл свои спер был ворой.\n",
            " Грет вылоски сон, — едянья\n",
            " И не богогой скухность:\n",
            " Платить за такой\n",
            " Урок платил\n",
            "Loss: 0.7217302405834198\n",
            " веритволе\n",
            " Скорей тщетные боги.\n",
            " Вод, твозвобосом свобода\n",
            " В седит и гразданье славы,\n",
            " То, чем дворца бы с высот\n",
            " Пать пор свободен.\n",
            " Но смертью уней росковом делиго могла.\n",
            " Ты можни смертью унем двор\n",
            "Loss: 0.6626832938194275\n",
            " веритвол провальимив,\n",
            " Ты был высол он ни бренный долона?\n",
            " Мир в венен, влек бредникий век\n",
            " Не вражданье она,\n",
            " Кто на бедный! Жертва славы,\n",
            " То, и ного нас дом сомовила.\n",
            " \n",
            " Тем надо оберванья\n",
            " Кас вод\n",
            "Loss: 0.6077822005748749\n",
            " верваво свет в пламя клиней\n",
            " Там, где падали мел он восмеет —\n",
            " Там, где пастушки тоскуют,\n",
            " Где другой притворство,\n",
            " И в нем на вольный стан встретил он грядущих лет;\n",
            " В нем он своих думал коне,\n",
            " Под с\n",
            "Loss: 0.5754023712873458\n",
            " осторе славить ли собой,\n",
            " Где сороб величии суровом,\n",
            " С презренный рода, — сон,\n",
            " Поль сети б в примерподной сетом\n",
            " Правсегда вылана?\n",
            " Тапой, скад нас власть мне верном,\n",
            " Платить за тиранов,\n",
            " Чем умен,\n",
            "Loss: 0.5222194159030914\n",
            " лед надоства и покой,\n",
            " Кровь наций яростно встретил он смертванный\n",
            " То водьжескиех дизда отренки больной,\n",
            " Где в праходом свое морями\n",
            " Вспоминать вашу добрелив т прамина,\n",
            " Не верних сердце грасть — не\n",
            "Loss: 0.48896492063999175\n",
            " осеча и павы сумел:\n",
            " Ствол сжался вновь, на собой,\n",
            " Чряне не жгучий родом.\n",
            " Пид друго могла она!\n",
            " О, свет в порывах слезам.\n",
            " \n",
            " Ваший ластья над расстратих к думы,\n",
            " Твой поздной роз высон,\n",
            " Покой лего,\n",
            "Loss: 0.4640096831321716\n",
            " онетоком богато,\n",
            " Но всем платил единой платой\n",
            " За верность мне кровь своих думал:\n",
            " Хотона бы с мечать презренья\n",
            " Казнит любимца поле,\n",
            " С которой гул молвы слодней глаза.\n",
            " Как вы, и он пылал когда-то,\n",
            "Loss: 0.4418274563550949\n",
            " остразлодит и грасть сломила?\n",
            " Уже слабеет влек быям моврагть,\n",
            " Призстуд нак прощаном встобя могла.\n",
            " Ты спошла же снежно-белом\n",
            " (С тобой покончили расстрей\n",
            " В седита, верность можешь над нем гордым!\n",
            " \n",
            "Loss: 0.4322326415777206\n",
            " вери твои замя в волной\n",
            " Ты мивых рока,\n",
            " Так всем платил позор вкирает властью небывалой,\n",
            " Как ты, упившись до славы,\n",
            " То огороненье\n",
            " Полюбил славы горит веские систином,\n",
            " Платить за титул и за кровью\n",
            "Loss: 0.40725280582904816\n",
            " великий в мире —\n",
            " Все парю призывам\n",
            " Тебя власть мечей,\n",
            " Сердца забились горячей;\n",
            " Здесь, на сонна не жалей, не тоскуй.\n",
            " Что Феб музагет! что парнасские хоры!\n",
            " Скоре — все пасть — и быть в живых!\n",
            " Ты \n",
            "Loss: 0.37880687952041625\n",
            " верит отмати, что раба скрыта:\n",
            " Ведь нынче и онае соне\n",
            " Полюбилась вдвойне.\n",
            " Французы дважды за такой\n",
            " Урок платили дорогой:\n",
            " Наполеон или Капет —\n",
            " В том для страны расстанций,\n",
            " Отмого собой наш друг.\n",
            "Loss: 0.36284953892230987\n",
            " верит обких памяти будет —\n",
            " Он — первый стыдливый любви поцелуй!\n",
            " \n",
            " Созданья мечты, где пастушки тоскуют,\n",
            " Где дремлют стада у задумчивых струй,\n",
            " Быть может, пленят, но души не знав кровавой\n",
            " И перава\n",
            "Loss: 0.35827851831912993\n",
            " веританый лить в порыва\n",
            " Щит с гербом, говорящий в унынии нам\n",
            " О баронах в броне, что вели горделиво\n",
            " Из Европы войска к палестинским пескам.\n",
            " \n",
            " Роберт сердца мне песней не жжет раскаленный\n",
            " В ерит и \n",
            "Loss: 0.35758785903453827\n",
            " веришь зном долыный трона?\n",
            " Вас для кровь кровь сердца льет оно!\n",
            " Зови покоренья мне все падели\n",
            " Страну волшебную мечтаний\n",
            " На царство Истины сменил!\n",
            " \n",
            " Проститься недогом ли б в тирасенья.\n",
            " К сквов д\n",
            "Loss: 0.35037737965583804\n",
            " осторе и ограда.\n",
            " Ты не смутишь урока из руг.\n",
            " \n",
            " Сточе славы час поворный стыдлины молчат?\n",
            " Да, есть! Он — первый стыдливый любви поцелуй!\n",
            " \n",
            " Пусть старость мне кровь беспощадно остудит,\n",
            " Ты, память б\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-5056c61a3c95>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-0c0c1fab3e5e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mht1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    880\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = TextRNN(input_size=len(idx_to_char), hidden_size=85, embedding_size=35, n_layers=2)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    patience=5,\n",
        "    verbose=True,\n",
        "    factor=0.5\n",
        ")\n",
        "\n",
        "n_epochs = 50000\n",
        "loss_avg = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    train, target = get_batch(sequence)\n",
        "    train = train.permute(1, 0, 2).to(device)\n",
        "    target = target.permute(1, 0, 2).to(device)\n",
        "    hidden = model.init_hidden(BATCH_SIZE)\n",
        "\n",
        "    output, hidden = model(train, hidden)\n",
        "    loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss_avg.append(loss.item())\n",
        "    if len(loss_avg) >= 50:\n",
        "        mean_loss = np.mean(loss_avg)\n",
        "        print(f'Loss: {mean_loss}')\n",
        "        scheduler.step(mean_loss)\n",
        "        loss_avg = []\n",
        "        model.eval()\n",
        "        predicted_text = evaluate(model, char_to_idx, idx_to_char)\n",
        "        print(predicted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "rv4Vy1r51h3a",
        "outputId": "97f22ea0-b850-4a18-9904-7f041a4fe942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". для кровью истекла:\n",
            " Та кровь исчезнуть не могла.\n",
            " Как смерч из океанских вод,\n",
            " Она из жгучих ран встает,\n",
            " Сливаясь в вихре горних сфер\n",
            " С твоей, герой Лабэдойер\n",
            " (Под бедный стыдливый любви поцелуй!\n",
            " \n",
            " Пусть старость мне кровь бескля кли.\n",
            " Смерть не воскромила —\n",
            " Там сперных дворцов,\n",
            " Не верить в друга, как в умеч — кок престоле.\n",
            " Ты ль покизонах струя\n",
            " В убий любви поцелуй!\n",
            " \n",
            " Не бойся, что Феб отвратит свои взоры,\n",
            " О помощи муз не жалей, не тоскуй.\n",
            " Что Феб музагет! что парнасские хоры!\n",
            " Заменит их первый любви поцелуй!\n",
            " \n",
            " Созданья мечты, где — облик брону?\n",
            " Ток одевы и погибнет уменья\n",
            " И пустоты — в тщеславье дев!\n",
            " \n",
            " Но знаю: ты лишь имя! Надо\n",
            " Сойти из облачных дворцов,\n",
            " Не верить в дру\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "print(evaluate(\n",
        "    model,\n",
        "    char_to_idx,\n",
        "    idx_to_char,\n",
        "    temp=0.3,\n",
        "    prediction_len=700,\n",
        "    start_text='. '\n",
        "    )\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}